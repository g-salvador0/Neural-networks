{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53ec440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79b874b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=400\n",
    "batch_size=16\n",
    "learning_rate=0.000001\n",
    "epocas=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b91d5130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,) (8937,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.,  8.,  1.,  5.,  2.,  1.,  6., 10.,  7.,  4.,  3.,  0.,  4.,\n",
       "        5.,  3.,  5.,  9.,  9.,  7.,  5.,  4.,  8.,  1.,  4.,  2.,  1.,\n",
       "        5., 10.,  7.,  4.,  3.,  0.,  4.,  5.,  4.,  5.,  9.,  9.,  7.,\n",
       "        5.,  4.,  7.,  1.,  4.,  2.,  1.,  5., 10.,  7.,  4.,  3.,  0.,\n",
       "        4.,  5.,  4.,  5.,  9.,  9.,  7.,  5.,  5.,  7.,  1.,  4.,  2.,\n",
       "        1.,  6., 10.,  6.,  4.,  3.,  0.,  4.,  5.,  4.,  5.,  9.,  9.,\n",
       "        7.,  5.,  5.,  7.,  1.,  3.,  2.,  1.,  6., 11.,  6.,  4.,  3.,\n",
       "        1.,  4.,  5.,  4.,  5.,  9.,  8.,  7.,  5.,  5.,  7.,  1.,  2.,\n",
       "        2.,  2.,  7., 11.,  6.,  4.,  2.,  1.,  4.,  5.,  4.,  5.,  9.,\n",
       "        8.,  7.,  5.,  4.,  7.,  1.,  3.,  3.,  2.,  7., 11.,  7.,  4.,\n",
       "        2.,  2.,  4.,  5.,  4.,  5.,  9.,  7.,  7.,  5.,  4.,  7.,  1.,\n",
       "        4.,  3.,  2.,  8., 12.,  7.,  4.,  2.,  2.,  4.,  5.,  4.,  5.,\n",
       "        9.,  7.,  7.,  5.,  5.,  6.,  1.,  3.,  3.,  2.,  8., 12.,  7.,\n",
       "        3.,  2.,  3.,  4.,  4.,  4.,  5., 10.,  7.,  8.,  6.,  6.,  7.,\n",
       "        1.,  3.,  3.,  2.,  8., 12.,  7.,  3.,  2.,  3.,  4.,  4.,  4.,\n",
       "        4., 10.,  7.,  8.,  6.,  6.,  7.,  1.,  3.,  3.,  2.,  8., 12.,\n",
       "        7.,  3.,  2.,  3.,  4.,  4.,  4.,  4., 11.,  7.,  8.,  6.,  6.,\n",
       "        7.,  1.,  3.,  3.,  2.,  8., 12.,  7.,  3.,  2.,  3.,  4.,  5.,\n",
       "        4.,  4., 11.,  7.,  8.,  6.,  7.,  7.,  1.,  3.,  3.,  2.,  8.,\n",
       "       13.,  7.,  4.,  2.,  3.,  4.,  5.,  4.,  4., 12.,  7.,  7.,  6.,\n",
       "        7.,  7.,  1.,  3.,  3.,  2.,  8., 13.,  7.,  5.,  2.,  3.,  4.,\n",
       "        5.,  4.,  4., 12.,  7.,  7.,  6.,  7.,  7.,  1.,  3.,  3.,  2.,\n",
       "        9., 13.,  7.,  5.,  2.,  3.,  4.,  5.,  5.,  4., 13.,  7.,  7.,\n",
       "        6.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste=np.load('dadosTeste.npy')\n",
    "dadosTreinoValidacao=np.load('dadosTreinoValidacao.npy')\n",
    "\n",
    "print(np.shape(dadosTreinoValidacao),\n",
    "np.shape(dados_teste))\n",
    "\n",
    "dadosTreinoValidacao[5200:5500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ea1abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000,) (20000,)\n"
     ]
    }
   ],
   "source": [
    "percentagem_dados=80\n",
    "\n",
    "x_train = dadosTreinoValidacao[:80000]\n",
    "\n",
    "x_validation = dadosTreinoValidacao[80000:]\n",
    "\n",
    "print(np.shape(x_train), np.shape(x_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ccd44d",
   "metadata": {},
   "source": [
    "### Dados treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5ddb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "def preparar_targets(x_train, length, batch_size):\n",
    "    d=5\n",
    "    salto=3 \n",
    "    n=d+salto #8\n",
    "    targets=[]\n",
    "    for i in range(len(x_train)):\n",
    "        soma = np.sum(x_train[d:n])\n",
    "        d= d+1\n",
    "        n= n+1\n",
    "        targets.append(soma)\n",
    "    del targets[-5:]\n",
    "    \n",
    "    targets = np.expand_dims(targets, axis=1)\n",
    "    \n",
    "    new = x_train[5:]\n",
    "    inputs = np.expand_dims(new, axis=1)\n",
    "\n",
    "    time_series_data = tf.keras.preprocessing.sequence.TimeseriesGenerator(inputs, targets, length= length, batch_size=batch_size)\n",
    "    \n",
    "    return time_series_data\n",
    "\n",
    "\n",
    "time_series_data = preparar_targets(x_train,length,batch_size)\n",
    "#time_series_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b057a6f",
   "metadata": {},
   "source": [
    "### Dados Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31165ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 400, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = preparar_targets(x_validation,length,batch_size)\n",
    "print(len(validation_data[0][0][0]))\n",
    "validation_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03149eb2",
   "metadata": {},
   "source": [
    "## Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2011a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "length = len(validation_data[0][0][0])\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0534a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, BatchNormalization\n",
    "\n",
    "\n",
    "cnnmodel = Sequential([Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(length, 1)),#precisa de dados 3D\n",
    "                       BatchNormalization(),\n",
    "                       tf.keras.layers.Activation(tf.keras.activations.relu),\n",
    "                       MaxPooling1D(pool_size=2),\n",
    "                       Conv1D(filters=128, kernel_size=2, activation='relu'),\n",
    "                       BatchNormalization(),       \n",
    "                       tf.keras.layers.Activation(tf.keras.activations.relu),\n",
    "                       MaxPooling1D(pool_size=2),\n",
    "                       Flatten(),\n",
    "                       Dense(64, activation='relu'),\n",
    "                       Dense(1)\n",
    "                      ])\n",
    "cnnmodel.compile(optimizer= keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics='mae')\n",
    "\n",
    "#cnnmodel.fit(time_series_data, epochs = epocas,validation_data = validation_data, shuffle= True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b9c4fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 400, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets= preparar_targets(dados_teste,length,batch_size)\n",
    "test_targets[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c26475d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 2s 4ms/step - loss: 253.2323 - mae: 15.3816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[253.23226928710938, 15.381580352783203]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnmodel.evaluate(test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3bbdb5",
   "metadata": {},
   "source": [
    "# Tunning Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91508e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    cnnmodel = Sequential([Conv1D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "                                  kernel_size=2,activation='relu', input_shape=(length, 1)),BatchNormalization()])#precisa de dados 3D\n",
    "    \n",
    "    #cnnmodel.add(tf.keras.layers.BatchNormalization())\n",
    "    cnnmodel.add(tf.keras.layers.Activation(tf.keras.activations.relu))\n",
    "    \n",
    "    for i in range(hp.Int('layers_',1,6)):\n",
    "        cnnmodel.add(MaxPooling1D(pool_size=2))\n",
    "        cnnmodel.add(Conv1D(filters=hp.Int('conv_1_filter'+str(i), min_value=32, max_value=128, step=16),\n",
    "                                  kernel_size=hp.Choice('conv_2_kernel', [2,5]),\n",
    "                                  activation='relu'))\n",
    "\n",
    "    cnnmodel.add(Flatten())\n",
    "    cnnmodel.add(Dense(hp.Int('last_dense', min_value=32, max_value=128, step=16), activation='relu'))\n",
    "    cnnmodel.add(Dense(1))\n",
    "                 \n",
    "    cnnmodel.compile(optimizer= keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics='mae')\n",
    "    \n",
    "    return cnnmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5369310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "tuner2 = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=5,hyperband_iterations=1,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99e13cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 06m 56s]\n",
      "val_loss: 24.277807235717773\n",
      "\n",
      "Best val_loss So Far: 20.007884979248047\n",
      "Total elapsed time: 03h 46m 11s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner2.search(time_series_data,epochs=5,validation_data=validation_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbaeff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001AAE7EDACA0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "layers_: 3\n",
      "conv_1_filter0: 48\n",
      "conv_2_kernel: 5\n",
      "last_dense: 112\n",
      "conv_1_filter1: 128\n",
      "conv_1_filter2: 96\n",
      "conv_1_filter3: 48\n",
      "conv_1_filter4: 64\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0002\n",
      "Score: 20.007884979248047\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "layers_: 3\n",
      "conv_1_filter0: 48\n",
      "conv_2_kernel: 5\n",
      "last_dense: 112\n",
      "conv_1_filter1: 128\n",
      "conv_1_filter2: 96\n",
      "conv_1_filter3: 48\n",
      "conv_1_filter4: 64\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 22.097244262695312\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 32\n",
      "layers_: 4\n",
      "conv_1_filter0: 96\n",
      "conv_2_kernel: 5\n",
      "last_dense: 80\n",
      "conv_1_filter1: 64\n",
      "conv_1_filter2: 128\n",
      "conv_1_filter3: 32\n",
      "conv_1_filter4: 64\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 24.277807235717773\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 112\n",
      "layers_: 4\n",
      "conv_1_filter0: 80\n",
      "conv_2_kernel: 2\n",
      "last_dense: 128\n",
      "conv_1_filter1: 96\n",
      "conv_1_filter2: 32\n",
      "conv_1_filter3: 64\n",
      "conv_1_filter4: 48\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0003\n",
      "Score: 24.55327033996582\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "layers_: 5\n",
      "conv_1_filter0: 64\n",
      "conv_2_kernel: 2\n",
      "last_dense: 128\n",
      "conv_1_filter1: 48\n",
      "conv_1_filter2: 32\n",
      "conv_1_filter3: 96\n",
      "conv_1_filter4: 112\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 24.73929214477539\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 112\n",
      "layers_: 4\n",
      "conv_1_filter0: 80\n",
      "conv_2_kernel: 2\n",
      "last_dense: 128\n",
      "conv_1_filter1: 96\n",
      "conv_1_filter2: 32\n",
      "conv_1_filter3: 64\n",
      "conv_1_filter4: 48\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 24.95752716064453\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 112\n",
      "layers_: 5\n",
      "conv_1_filter0: 32\n",
      "conv_2_kernel: 5\n",
      "last_dense: 64\n",
      "conv_1_filter1: 80\n",
      "conv_1_filter2: 80\n",
      "conv_1_filter3: 48\n",
      "conv_1_filter4: 80\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 25.17340850830078\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "layers_: 4\n",
      "conv_1_filter0: 48\n",
      "conv_2_kernel: 5\n",
      "last_dense: 112\n",
      "conv_1_filter1: 32\n",
      "conv_1_filter2: 128\n",
      "conv_1_filter3: 112\n",
      "conv_1_filter4: 96\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 25.33062744140625\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 96\n",
      "layers_: 4\n",
      "conv_1_filter0: 32\n",
      "conv_2_kernel: 5\n",
      "last_dense: 96\n",
      "conv_1_filter1: 80\n",
      "conv_1_filter2: 96\n",
      "conv_1_filter3: 112\n",
      "conv_1_filter4: 128\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 25.575876235961914\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "conv_1_filter: 64\n",
      "layers_: 5\n",
      "conv_1_filter0: 64\n",
      "conv_2_kernel: 5\n",
      "last_dense: 48\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "conv_1_filter1: 32\n",
      "conv_1_filter2: 32\n",
      "conv_1_filter3: 32\n",
      "conv_1_filter4: 32\n",
      "Score: 26.774240493774414\n"
     ]
    }
   ],
   "source": [
    "tuner2.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f9642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
